{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in the swarm passes over our event. To do this we need to:\n",
    "\n",
    "A: Plot the Images\n",
    "\n",
    "B: Get the emphermis data for swarm B\n",
    "\n",
    "C: Find the footprint of swarm B at the assumed emission height of 110km\n",
    "\n",
    "D: Overplot the emphermis data with the ground based observations\n",
    "\n",
    "E: Overplot the velocity quivers with ground based observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Lets first grab our images from the package asilib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Lets choose a 3x2 grid to plot the images, our images will start at 14:04.20 and then move 10 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #Lets handle our imports now for section A\n",
    "import matplotlib.pyplot as plt\n",
    "import asilib\n",
    "import asilib.asi\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.optimize import curve_fit\n",
    "import scienceplots\n",
    "\n",
    "plt.style.use(['science', 'no-latex'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want a 3x3 pannel with 10 second intervals at altitude of 150km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time= datetime(2022,12,19,14,4,20)\n",
    "time_array= [start_time + timedelta(seconds=10*x) for x in range(9)]\n",
    "alt=150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=3, dpi=300)\n",
    "axlist=axes.flatten()\n",
    "plt.axis('off')\n",
    "\n",
    "for i in range(len(time_array)):\n",
    "    asi=asilib.asi.trex_rgb(location_code='yknf', alt=alt, time=time_array[i])\n",
    "\n",
    "    asi.plot_fisheye(ax=axlist[i], label=False, cardinal_directions='NEWS')\n",
    "    axlist[i].set_axis_off()\n",
    "    axlist[i].set_title(time_array[i].strftime('%H:%M:%S%f')[:-6])\n",
    "plt.tight_layout(pad=0.1, w_pad=0.6, h_pad=-1)\n",
    "plt.savefig(\"test.png\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets move onto part B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the viresclient ESA client to download swarm empharmsis data with a frequency that matches the cadence of 3 so that it matches with the cadence of trex rgb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from viresclient import set_token\n",
    "from viresclient import SwarmRequest\n",
    "import geopack.geopack as gp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we need to set our token, for my case to protect my token I import from a file not in the github cloud, however you can just paste your code from viresclient, just don't share it publically!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From documentation link\n",
    "def requester(sc_collection, measurement, residual, sampling_step=None, **kwargs):\n",
    "    try:\n",
    "        request = SwarmRequest()\n",
    "        request.set_collection(sc_collection)\n",
    "        if residual == True:\n",
    "            request.set_products(\n",
    "                measurements=measurement,\n",
    "                models=[\"CHAOS\"],\n",
    "                residuals=True,\n",
    "                sampling_step=sampling_step,\n",
    "            )\n",
    "        else:\n",
    "            request.set_products(\n",
    "                measurements=measurement,\n",
    "                models=[\"CHAOS\"],\n",
    "                sampling_step=sampling_step,\n",
    "            )\n",
    "        data = request.get_between(time_array[0], time_array[-1]+timedelta(seconds=10), **kwargs) #sets to get data between the first and last value in time array iniatialized earlier\n",
    "        df = data.as_dataframe()\n",
    "    except:\n",
    "        df = []\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = requester( \n",
    "    \"SW_OPER_MAGB_LR_1B\", #Mag B, low resolution, 1Hz B (Magnetic field)\n",
    "    \"B_NEC\", #Magnetic field in NEC coordinates\n",
    "    True, \n",
    "    asynchronous=False,\n",
    "    show_progress=False,\n",
    "    sampling_step=\"PT{}S\".format(10)) #cadence of 10 to match our images, in practice this selects every 10th data point since the resolution is 1 sample a second (sps)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude, longitude, altitude = ds['Latitude'].to_numpy(), ds['Longitude'].to_numpy(),  (ds[\"Radius\"].to_numpy()-6.371e6)/1e3 #km  # Gets Emphermis data\n",
    "print(ds.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good now that we have empharsis we need to find the footprint. To do this, we use geopack and asilib. Alternatively if you have IRBEM installed you can use asilib.conjunction.footprint to do this automagically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time_array[0]\n",
    "t0 = datetime(1970,1,1)\n",
    "ut = (t1-t0).total_seconds()\n",
    "lat_sat=np.deg2rad(latitude)\n",
    "lon_sat=np.deg2rad(longitude)\n",
    "gp.recalc(ut)\n",
    "print(altitude)\n",
    "r, theta= gp.geodgeo(altitude,lat_sat,1) #TODO magically, r is 10km less than if you calculated r manually, is this real\n",
    "\n",
    "x_gc,y_gc,z_gc = gp.sphcar((r)/6371,theta,lon_sat,1)  #spherical to cartesian\n",
    " \n",
    "\n",
    "x_gsm, y_gsm, z_gsm = gp.geogsm(x_gc,y_gc,z_gc, 1) #cartesian to gsm\n",
    "\n",
    "x_foot,y_foot,z_foot=np.zeros(len(x_gsm)), np.zeros(len(y_gsm)), np.zeros(len(z_gsm)) #initalize an array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(x_gsm)):\n",
    "    x_foot_int, y_foot_int, z_foot_int, xx2, yy2,zz2 = gp.trace(x_gsm[index], y_gsm[index], z_gsm[index], dir=1,rlim=2, r0=(alt-10+6371)/6371, maxloop=300 ) #traces each set of lat,lon,alt outward\n",
    "    def curve_fit_func():\n",
    "        def cubic(t, a, b, c, d):\n",
    "            return a*t**3 + b*t**2 + c*t + d\n",
    "        r = np.linspace(1, 1.5, 100000)\n",
    "\n",
    "        radius_data=np.sqrt(xx2**2+yy2**2+zz2**2)\n",
    "\n",
    "        params_x, _ = curve_fit(cubic, radius_data, xx2) #Constructs fits on the traces inward since the spatial resolution produced by geopack is limited.\n",
    "        params_y, _ = curve_fit(cubic, radius_data, yy2)\n",
    "        params_z, _ = curve_fit(cubic, radius_data, zz2)\n",
    "\n",
    "        def x(t):\n",
    "            return cubic(t, *params_x)\n",
    "\n",
    "        def y(t):\n",
    "            return cubic(t, *params_y)\n",
    "\n",
    "        def z(t):\n",
    "            return cubic(t, *params_z)\n",
    "        def radius(t):\n",
    "            return np.sqrt(x(t)**2 + y(t)**2 + z(t)**2)\n",
    "\n",
    "        index_closest=np.argmin(np.abs(radius(r)-(alt-10+6371)/6371))\n",
    "\n",
    "        return x(r[index_closest]),y(r[index_closest]),z(r[index_closest])\n",
    "\n",
    "    x_foot[index],y_foot[index],z_foot[index] = curve_fit_func()\n",
    "\n",
    "x_done, y_done, z_done = gp.geogsm(x_foot, y_foot, z_foot, -1)\n",
    "\n",
    "alt_sat_done, lat_sat_done,lon_sat_done = np.zeros(len(x_done)), np.zeros(len(x_done)), np.zeros(len(x_done))\n",
    "for index in range(len(x_done)):\n",
    "    \n",
    "    r_done,theta_done,lon_sat_done[index]= gp.sphcar(x_done[index], y_done[index], z_done[index],-1)\n",
    "\n",
    "    alt_sat_done[index], lat_sat_done[index]= gp.geodgeo(r_done*6371,theta_done,-1) #TODO check if this is right\n",
    "\n",
    "print(alt_sat_done, 'altitude derived from fit')\n",
    "\n",
    "if np.any(np.abs(alt_sat_done - alt) > 5):\n",
    "    raise Exception(\"One or more values in the footprinting are greater than 5km away from the specified alt. Contact owner for a fix, not your fault\")\n",
    "print(np.rad2deg(lon_sat_done)-360,np.rad2deg(lat_sat_done) , 'lat and lon' )\n",
    "sat_lla=np.array([np.rad2deg(lat_sat_done), np.rad2deg(lon_sat_done)-360, alt_sat_done]).T\n",
    "\n",
    "conjunction_obj = asilib.Conjunction(asi, (np.array(time_array), sat_lla))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets use asilib to synthsize the empharsis data with the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_azel, sat_azel_pixels = conjunction_obj.map_azel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"axes.edgecolor\"] = \"0.15\"\n",
    "plt.rcParams[\"axes.linewidth\"]  = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(10,8), nrows=3, ncols=3, dpi=300)\n",
    "axlist=axes.flatten()\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "for i in range(len(time_array)):\n",
    "    asi=asilib.asi.trex_rgb(location_code='yknf', alt=alt, time=time_array[i])\n",
    "\n",
    "    asi.plot_fisheye(ax=axlist[i], label=False, cardinal_directions='NW')\n",
    "    axlist[i].set_axis_off()\n",
    "    axlist[i].set_title(time_array[i].strftime('%H:%M:%S%f')[:-6], fontsize=18)\n",
    "    print(time_array[i].strftime('%H:%M:%S%f')[:-6],  time_array[i])\n",
    "print(sat_azel_pixels[:, 1], time_array)\n",
    "for i in range(len(axlist)):\n",
    "    axlist[i].plot(sat_azel_pixels[:, 0],\n",
    "                            sat_azel_pixels[:, 1], color='red', linestyle=\"dashed\")\n",
    "    axlist[i].scatter(sat_azel_pixels[i, 0], sat_azel_pixels[i, 1],\n",
    "                marker='o', s=5, color='red')\n",
    "plt.subplots_adjust(hspace=0.15, wspace=-0.2)  # Adjust the value as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(10,8), nrows=3, ncols=3, dpi=300)\n",
    "axlist=axes.flatten()\n",
    "\n",
    "for i in range(len(time_array)):\n",
    "    asi=asilib.asi.trex_rgb(location_code='yknf', alt=alt, time=time_array[i], colors='rgb')\n",
    "\n",
    "    asi.plot_map(ax=axlist[i], asi_label=False)\n",
    "    axlist[i].set_ylim(59, 66)\n",
    "    axlist[i].set_title(time_array[i].strftime('%H:%M:%S%f')[:-6])\n",
    "    axlist[i].plot(sat_lla[:,1], sat_lla[:,0], color='red', linestyle='dashed')\n",
    "    axlist[i].scatter(sat_lla[i,1], sat_lla[i,0], color='blue')\n",
    "plt.savefig(\"test.png\",bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(10,8), nrows=3, ncols=3, dpi=300, sharex=True, sharey=True, tight_layout=True)\n",
    "\n",
    "axlist=axes.flatten()\n",
    "\n",
    "for i in range(len(time_array)):\n",
    "    axlist[i].tick_params(axis='both', colors='white', labelcolor='black')\n",
    "    asi=asilib.asi.trex_rgb(location_code='yknf', alt=alt, time=time_array[i], colors='rgb')\n",
    "\n",
    "    asi.plot_map(ax=axlist[i], asi_label=False)\n",
    "    axlist[i].set_title(time_array[i].strftime('%H:%M:%S%f')[:-6])\n",
    "    axlist[i].set_xlim(-119,-111)\n",
    "    axlist[i].set_ylim(61.75,63)\n",
    "    axlist[i].plot(sat_lla[:,1], sat_lla[:,0], color='white', linestyle='dashed')\n",
    "    axlist[i].scatter(sat_lla[i,1], sat_lla[i,0], color='red')\n",
    "plt.savefig(\"test.png\")\n",
    "fig.suptitle(\"Track of Swarm B Over Auroral Vortices\")\n",
    "fig.supxlabel(\"Geographic Longitude\", y=0.02)\n",
    "fig.supylabel(\"Geographic Latitude\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to had velocity quivers to our plot for added context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From documentation link\n",
    "def requester(sc_collection, measurement, residual, sampling_step=None, **kwargs):\n",
    "    try:\n",
    "        request = SwarmRequest()\n",
    "        request.set_collection(sc_collection)\n",
    "        if residual == True:\n",
    "            request.set_products(\n",
    "                measurements=measurement,\n",
    "                models=[\"CHAOS\"],\n",
    "                residuals=True,\n",
    "                sampling_step=sampling_step,\n",
    "            )\n",
    "        else:\n",
    "            request.set_products(\n",
    "                measurements=measurement,\n",
    "                models=[\"CHAOS\"],\n",
    "                sampling_step=sampling_step,\n",
    "            )\n",
    "        data = request.get_between(time_array[0], time_array[-1], **kwargs) #sets to get data between the first and last value in time array iniatialized earlier\n",
    "        df = data.as_dataframe()\n",
    "    except:\n",
    "        df = []\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements_E = [\n",
    "        \"VsatN\",\n",
    "        \"VsatE\",\n",
    "        \"VsatC\",\n",
    "        \"Evx\",\n",
    "        \"Evy\",\n",
    "        \"Evz\",\n",
    "        \"Vixv\",\n",
    "        \"Viy\",\n",
    "        \"Viz\",\n",
    "        \"Quality_flags\",\n",
    "    ]\n",
    "dsE = requester( \n",
    "    \"SW_EXPT_EFIB_TCT16\", #Mag B, high resolution, 50Hz B (Magnetic field)\n",
    "    measurements_E, #Magnetic field in NEC coordinates\n",
    "    True, \n",
    "    asynchronous=False,\n",
    "    show_progress=False) \n",
    "dsB = requester( \n",
    "    'SW_OPER_MAGB_HR_1B', #Mag B, high resolution, 50Hz B (Magnetic field)\n",
    "    [\"q_NEC_CRF\"], #Magnetic field in NEC coordinates\n",
    "    False, \n",
    "    asynchronous=False,\n",
    "    show_progress=False)\n",
    "Etime = dsE[\"Viy\"].index.to_numpy()\n",
    "Btime = dsB['Latitude'].index.to_numpy()\n",
    "latitude_B, longitude_B, altitude_B = dsB['Latitude'].to_numpy(), dsB['Longitude'].to_numpy(),  (dsB[\"Radius\"].to_numpy()-6.371e6)/1e3 #km  # Gets Emphermis data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.optimize import curve_fit\n",
    "import geopack.geopack as gp\n",
    "def footprint(time, latitude, longitude, altitude, alt,vsw= [-400,0,0]):\n",
    "    \"\"\"\n",
    "    time, datetime, time for magnetic data for footprint\n",
    "    vsw velocity of solar wind, tuple of x,y,z\n",
    "    longitude of satellite in degrees\n",
    "    latitude of satellite in degrees\n",
    "    altitude of satellite in km from centre of earth (should be above ~6371)\n",
    "    THIS CODE ONLY Works in the NOrthern hemisphere\n",
    "\n",
    "    \"\"\"\n",
    "    def cubic(t, a, b, c, d):\n",
    "            return a*t**3 + b*t**2 + c*t + d\n",
    "    def x(t, params_x):\n",
    "        return cubic(t, *params_x)\n",
    "\n",
    "    def y(t, params_y):\n",
    "        return cubic(t, *params_y)\n",
    "\n",
    "    def z(t, params_z):\n",
    "        return cubic(t, *params_z)\n",
    "    def radius(t, params_x, params_y, params_z):\n",
    "        return np.sqrt(x(t, params_x)**2 + y(t, params_y)**2 + z(t, params_z)**2)\n",
    "    \n",
    "    def curve_fit_func(xx,yy,zz, differencealt):\n",
    "        \n",
    "        r = np.linspace(1, 1.5, 10000)# construct an array of radiuses from 1-1.5\n",
    "\n",
    "        radius_data=np.sqrt(xx**2+yy**2+zz**2)\n",
    "\n",
    "        params_x, _ = curve_fit(cubic, radius_data, xx) #Constructs fits on the traces inward since the spatial resolution produced by geopack is limited.\n",
    "        params_y, _ = curve_fit(cubic, radius_data, yy)\n",
    "        params_z, _ = curve_fit(cubic, radius_data, zz)\n",
    "\n",
    "        \n",
    "\n",
    "        index_closest=np.argmin(np.abs(radius(r, params_x, params_y, params_z)-(alt-differencealt+6371)/6371))#Find the index that produces the closest radius to the altitude\n",
    "\n",
    "        return x(r[index_closest],params_x ),y(r[index_closest],params_y ),z(r[index_closest],params_z )\n",
    "    \n",
    "    t1 = time\n",
    "    t0 = datetime(1970,1,1) #epoch\n",
    "    ut = (t1-t0).total_seconds()\n",
    "    lat_sat=np.deg2rad(latitude)\n",
    "    lon_sat=np.deg2rad(longitude) #converts to radii\n",
    "    gp.recalc(ut)\n",
    "    r, theta= gp.geodgeo(altitude,lat_sat,1) #this r accounts for earths oblateness, so we need to find the difference between my 6371 assumption and the real value and account for that\n",
    "    differencearray= (altitude+6371)-r\n",
    "    x_gc,y_gc,z_gc = gp.sphcar((r)/6371,theta,lon_sat,1)  #spherical to cartesian\n",
    "    \n",
    "\n",
    "    x_gsm, y_gsm, z_gsm = gp.geogsm(x_gc,y_gc,z_gc, 1) #cartesian to gsm\n",
    "\n",
    "    x_foot,y_foot,z_foot=np.zeros(len(x_gsm)), np.zeros(len(y_gsm)), np.zeros(len(z_gsm)) #initalize an array\n",
    "    for index in range(len(x_gsm)):\n",
    "        x_foot_int, y_foot_int, z_foot_int, xx2, yy2,zz2 = gp.trace(x_gsm[index], y_gsm[index], z_gsm[index], dir=1,rlim=3, maxloop=1000 ) #traces each set of lat,lon,alt outward\n",
    "\n",
    "\n",
    "        x_foot[index],y_foot[index],z_foot[index] = curve_fit_func(xx2,yy2,zz2, differencearray[index])\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "    x_done, y_done, z_done = gp.geogsm(x_foot, y_foot, z_foot, -1)\n",
    "\n",
    "    alt_sat_done, lat_sat_done,lon_sat_done = np.zeros(len(x_done)), np.zeros(len(x_done)), np.zeros(len(x_done))\n",
    "    for index in range(len(x_done)):\n",
    "        \n",
    "        r_done,theta_done,lon_sat_done[index]= gp.sphcar(x_done[index], y_done[index], z_done[index],-1)\n",
    "\n",
    "        alt_sat_done[index], lat_sat_done[index]= gp.geodgeo(r_done*6371,theta_done,-1) #TODO check if this is right\n",
    "\n",
    "    print(alt_sat_done, 'altitude derived from fit')\n",
    "\n",
    "    if np.any(np.abs(alt_sat_done - alt) > 5):\n",
    "        raise Exception(\"One or more values in the footprinting are greater than 5km away from the specified alt. Contact owner for a fix, not your fault\")\n",
    "    print(np.rad2deg(lon_sat_done)-360,np.rad2deg(lat_sat_done) , 'lat and lon' )\n",
    "    sat_lla=np.array([ np.rad2deg(lat_sat_done), np.rad2deg(lon_sat_done)-360,  alt_sat_done])\n",
    "    return sat_lla\n",
    "\n",
    "\n",
    "def find_closest_indices(times1, times2):\n",
    "    # Convert to numpy arrays\n",
    "    times1 = np.array(times1)\n",
    "    times2 = np.array(times2)\n",
    "    \n",
    "    # Compute the differences between each time in times1 and all times in times2\n",
    "    # Resulting in a 2D array where each row contains the absolute differences for one time in times1\n",
    "    differences = np.abs(times1[:, None] - times2)\n",
    "    \n",
    "    # Find the index of the minimum difference for each time in times1\n",
    "    closest_indices = np.argmin(differences, axis=1)\n",
    "    \n",
    "    return closest_indices\n",
    "\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import numpy as np\n",
    "\n",
    "def quaternion_inverse_scipy(q):\n",
    "    # Ensure q is a numpy array\n",
    "    q = np.asarray(q)\n",
    "    \n",
    "    # Create a Rotation object from the quaternion\n",
    "    rotation = R.from_quat(q)  # Note: scipy uses [x, y, z, w] format\n",
    "    \n",
    "    # Compute the inverse rotation\n",
    "    inverse_rotation = rotation.inv()\n",
    "    \n",
    "    \n",
    "    return inverse_rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_lla_B=footprint(time_array[0], latitude_B, longitude_B, altitude_B, alt, vsw=[-345,12,-12])\n",
    "#This can take 10+ minutes, sry but I wanted to make my own pythonic-based footprinter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicies=find_closest_indices(dsE.index, dsB.index)\n",
    "quatnecrf=dsB[\"q_NEC_CRF\"].to_numpy()[indicies]\n",
    "quaternions = []\n",
    "vsat=np.array([dsE[\"Vixv\"] , dsE[\"Viy\"], dsE[\"Viz\"]]).T\n",
    "Etime = dsE.index\n",
    "ENEC=[]\n",
    "VNEC=[]\n",
    "for i in range(len(quatnecrf)):\n",
    "    inverse_quat = quaternion_inverse_scipy(dsB[\"q_NEC_CRF\"].to_numpy()[indicies][i])\n",
    "\n",
    "    rot_NEC_V= inverse_quat.apply(vsat[i])\n",
    "    VNEC.append(rot_NEC_V)\n",
    "\n",
    "ENEC=np.array(ENEC)\n",
    "VNEC=np.array(VNEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import CubicSpline\n",
    "cs_lat = CubicSpline( Btime, sat_lla_B[0])\n",
    "cs_lon = CubicSpline( Btime, sat_lla_B[1])\n",
    "cs_alt = CubicSpline( Btime, sat_lla_B[2])\n",
    "\n",
    "#sat_lla_E=footprint(time_array[0], latitude_E, longitude_E, altitude_E, alt, vsw=[-345,12,-12])\n",
    "sat_lla_E= np.array([cs_lat(Etime), cs_lon(Etime),  cs_alt(Etime)]) #km  # Gets Emphermis data latitude, longitude, altitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_perpendicular = -VNEC[:, 1] / 2000  # Inverting y-component for perpendicular direction\n",
    "V_perpendicular = VNEC[:, 1] / 2000   # Keeping the x-component\n",
    "u_zeros = np.zeros_like(VNEC[:, 1])\n",
    "QV1= plt.quiver( Etime,sat_lla_E[0], V_perpendicular, u_zeros, color='white', scale=1, scale_units='inches', label=\"Eastward Velocity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize=(10,8), nrows=3, ncols=3, dpi=300, sharex=True, sharey=True, tight_layout=True)\n",
    "\n",
    "axlist=axes.flatten()\n",
    "\n",
    "for i in range(len(time_array)):\n",
    "    axlist[i].tick_params(axis='both', colors='white', labelcolor='black', which='both')\n",
    "    asi=asilib.asi.trex_rgb(location_code='yknf', alt=alt, time=time_array[i], colors='rgb')\n",
    "\n",
    "    asi.plot_map(ax=axlist[i], asi_label=False)\n",
    "    axlist[i].set_title(time_array[i].strftime('%H:%M:%S%f')[:-6])\n",
    "    axlist[i].set_xlim(-119,-109)\n",
    "    axlist[i].set_ylim(61.75,63)\n",
    "    axlist[i].quiver(sat_lla_E[1], sat_lla_E[0],V_perpendicular, u_zeros, color='white', scale=1.9, scale_units='inches', label=\"Eastward Velocity\", alpha=0.2)\n",
    "    indicies= np.where((Etime >= np.datetime64(time_array[i] -  timedelta(seconds=6))) & (Etime <= np.datetime64(time_array[i] + timedelta(seconds=6))))[0]\n",
    "    axlist[i].quiver(sat_lla_E[1][indicies], sat_lla_E[0][indicies],V_perpendicular[indicies], u_zeros[indicies], color='red', scale=1.90, scale_units='inches', label=\"Eastward Velocity\", alpha=0.4)\n",
    "    middle_index=np.argmin(np.abs(Etime -time_array[i]))\n",
    "    axlist[i].scatter(sat_lla_E[1][middle_index], sat_lla_E[0][middle_index], color='white', s=25)\n",
    "plt.savefig(\"test.png\")\n",
    "fig.suptitle(\"Track of Swarm B Over Auroral Vortices\")\n",
    "fig.supxlabel(\"Geographic Longitude\", y=0.02)\n",
    "fig.supylabel(\"Geographic Latitude\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
